{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"slim\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object-detection made easy\n",
    "We will learn how to easily train an object detection model from a list of pre-trained models with the dataset you created on the picsell-IA platform."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from picsellia import Client\n",
    "import main\n",
    "from util.infer import infer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## List of possible models : \n",
    "\n",
    "- Mask RCNN, a segmentation model. String variable: 'mask_rcnn'\n",
    "- Faster RCNN an accurate but slow object detection model. String variable: 'faster_rcnn'\n",
    "- SSD Inception, a fast but less accurate object detection model. String variable : 'ssd_inception'\n",
    "\n",
    "## Setup\n",
    "\n",
    "We need to start setting up some variables before everything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "token = \"f2a5daec-e0cc-4ea8-a5eb-10d04fd1e153\" # Token from the picsell-IA platform\n",
    "model_picked = \"faster_rcnn\" # Choose your base model here from the list of possible models\n",
    "model_name = \"faster_rcnn\" # Name your to-be trained model\n",
    "annotation_type = \"rectangle\" # Chose the type of annotation used\n",
    "\n",
    "batch_size = 1\n",
    "learning_rate = None #You can let this value to None\n",
    "nb_steps = 20000\n",
    "mask_type = None #Set this to 'PNG_MASKS' if you want to train a mask segmentation model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Client initialisation and data pre-processing\n",
    "\n",
    "We communicate with the platform to create a new model and get the images and annotations.\n",
    "With this we can generate the label map, smartly split our data then create the TFRecord files which will be used as input for the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path_models = \"models/\"\n",
    "model_selected = path_models + model_picked + \"/\"\n",
    "\n",
    "clt = Client(token=token, host=\"https://backstage.picsellia.com/sdk/\")\n",
    "clt.init_model(model_name)\n",
    "\n",
    "clt.dl_annotations()\n",
    "clt.generate_labelmap()\n",
    "clt.local_pic_save()\n",
    "\n",
    "main.create_record_files(label_path=clt.label_path, record_dir=clt.record_dir, \n",
    "                         tfExample_generator=clt.tf_vars_generator, annotation_type=annotation_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we edit the base protobuf configuration of our model with our parameters. \n",
    "We check if it the first training on this model to see if we should train from a previous checkpoint or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if clt.training_id!=0:\n",
    "    previous_path = clt.base_dir.split(\"/\")[:-1]\n",
    "    previous_path[-1] = clt.training_id - 1\n",
    "    model_selected = \"{}/{}/{}/\".format(*previous_path)+\"checkpoint/\"\n",
    "    \n",
    "main.edit_config(model_selected=model_selected, config_output_dir=clt.config_dir,\n",
    "            record_dir=clt.record_dir, \n",
    "            label_map_path=clt.label_path, \n",
    "            masks=mask_type, \n",
    "            num_steps=nb_steps,\n",
    "            batch_size=batch_size, \n",
    "            learning_rate=learning_rate,\n",
    "            training_id=clt.training_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We can launch the training... and it's as easy as just telling the fonction where is the configuration file and where we want the checkpoints and records to be saved !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main.legacy_train(ckpt_dir=clt.checkpoint_dir, \n",
    "                     conf_dir=clt.config_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the training has ended we want to send the logs to our dashboard so we can neatly see the sweet decrease of the loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dict_log = main.tfevents_to_dict(path=clt.checkpoint_dir)\n",
    "clt.send_logs(dict_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exporting and infering\n",
    "\n",
    "The model is trained but we still need to export it to a Tensorflow graph proto to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "main.export_infer_graph(ckpt_dir=clt.checkpoint_dir, \n",
    "                       exported_model_dir=clt.exported_model, \n",
    "                       pipeline_config_path=clt.config_dir,\n",
    "                       write_inference_graph=True, input_type=\"image_tensor\", input_shape=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will use the exported model to do some inference on our evaluation set, then send the results to the dashboard.\n",
    "You can set the minimum confidence treshold at which we keep the bounding boxes to the value you like the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "min_score_thresh = 0.6 \n",
    "infer(clt.eval_list, exported_model_dir=clt.exported_model, \n",
    "          label_map_path=clt.label_path, results_dir=clt.results_dir, min_score_thresh=min_score_thresh)\n",
    "clt.send_examples()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
