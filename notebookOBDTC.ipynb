{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZaoLlAKrK41G"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/BouleJaune/picselliaT/blob/master/notebookOBDTC.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6t3am_CDKjWU"
   },
   "source": [
    "# Object-detection made easy\n",
    "We will learn how to easily train an object detection model from a list of pre-trained models with the dataset you created on the picsell-IA platform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 641
    },
    "colab_type": "code",
    "id": "bS6pLrgacUg7",
    "outputId": "2e1551d5-e572-49e9-ffd0-a324b80bdc06"
   },
   "outputs": [],
   "source": [
    "!git clone https://github.com/BouleJaune/picselliaT\n",
    "%cd picselliaT/\n",
    "!pip install picsellia\n",
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XhntBjQuKjWV"
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164
    },
    "colab_type": "code",
    "id": "ZeMjhE6jKjWY",
    "outputId": "bbfc2840-bc5c-4cc6-e693-bd95b4c84b66",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.append(\"slim\")\n",
    "from picsellia import Client\n",
    "import main\n",
    "from util.infer import infer\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MYlIZgv9KjWe"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "## List of possible models : \n",
    "\n",
    "- Mask RCNN, a segmentation model. String variable: 'mask_rcnn'\n",
    "- Faster RCNN an accurate but slow object detection model. String variable: 'faster_rcnn'\n",
    "- SSD Inception, a fast but less accurate object detection model. String variable : 'ssd_inception'\n",
    "\n",
    "## Setup\n",
    "\n",
    "We need to start setting up some variables before anything else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5g9FPMCdKjWg",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "project_token = \"d8e83b34-352e-41b1-9329-03a791f8d4ef\" # Token from the picsell-IA platform\n",
    "api_token = \"5890ad3e6a9701cd123ef91b69ad396de8c2d20a\"\n",
    "model_name = \"base_maskrcnn\" # Name your to-be trained model\n",
    "annotation_type = \"polygon\" # Chose the type of annotation used\n",
    "\n",
    "batch_size = 1\n",
    "learning_rate = None #You can let this value to None\n",
    "nb_steps = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UPNfFH5_KjWl"
   },
   "source": [
    "## Client initialisation and data pre-processing\n",
    "\n",
    "We communicate with the platform to create a new model and get the images and annotations.\n",
    "With this we can generate the label map, smartly split our data then create the TFRecord files which will be used as input for the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 550
    },
    "colab_type": "code",
    "id": "dUq-cDBVKjWm",
    "outputId": "cc07db90-dc7f-4bfe-b23d-b8263471e90c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome Xenio3, Please initialize your project with init_project() and the project token provided on the platform\n",
      "Available project : \n",
      "\n",
      "\t mask-classification\n",
      "\t careden_train\n",
      "{'project_token': 'd8e83b34-352e-41b1-9329-03a791f8d4ef'}\n",
      "Welcome to Picsell.ia Client, this project_token is linked to your project : careden_train\n",
      "This is a detection project\n",
      "Here is the current state of your project:\n",
      "\n",
      "---------------\n",
      "4 training version(s) for Network named : car_bruises_mask_rcnn\n",
      "---------------\n",
      "\t For training id 0:\n",
      "\n",
      "\t\t Train Test Set repartition : DONE\n",
      "\t\t Visual results uploaded to Picsell.ia : DONE\n",
      "\t\t Training logs uploaded to Picsell.ia : DONE\n",
      "\t\t Model usable from Picsell.ia : DONE\n",
      "\t For training id 1:\n",
      "\n",
      "\t\t Train Test Set repartition : DONE\n",
      "\t\t Visual results uploaded to Picsell.ia : NOT DONE\n",
      "\t\t Training logs uploaded to Picsell.ia : DONE\n",
      "\t\t Model usable from Picsell.ia : DONE\n",
      "\t For training id 2:\n",
      "\n",
      "\t\t Train Test Set repartition : NOT DONE\n",
      "\t\t Visual results uploaded to Picsell.ia : NOT DONE\n",
      "\t\t Training logs uploaded to Picsell.ia : DONE\n",
      "\t\t Model usable from Picsell.ia : DONE\n",
      "\t For training id 3:\n",
      "\n",
      "\t\t Train Test Set repartition : DONE\n",
      "\t\t Visual results uploaded to Picsell.ia : DONE\n",
      "\t\t Training logs uploaded to Picsell.ia : NOT DONE\n",
      "\t\t Model usable from Picsell.ia : DONE\n",
      "---------------\n",
      "3 training version(s) for Network named : base_maskrcnn\n",
      "---------------\n",
      "\t For training id 0:\n",
      "\n",
      "\t\t Train Test Set repartition : NOT DONE\n",
      "\t\t Visual results uploaded to Picsell.ia : DONE\n",
      "\t\t Training logs uploaded to Picsell.ia : NOT DONE\n",
      "\t\t Model usable from Picsell.ia : DONE\n",
      "\t For training id 1:\n",
      "\n",
      "\t\t Train Test Set repartition : DONE\n",
      "\t\t Visual results uploaded to Picsell.ia : NOT DONE\n",
      "\t\t Training logs uploaded to Picsell.ia : NOT DONE\n",
      "\t\t Model usable from Picsell.ia : DONE\n",
      "\t For training id 2:\n",
      "\n",
      "\t\t Train Test Set repartition : DONE\n",
      "\t\t Visual results uploaded to Picsell.ia : NOT DONE\n",
      "\t\t Training logs uploaded to Picsell.ia : NOT DONE\n",
      "\t\t Model usable from Picsell.ia : DONE\n",
      "{'network_id': '4b0d7fdd-6e9b-443a-a44e-a8b1508ce4bc', 'training_id': 3, 'checkpoints': {'config_file': 'd8e83b34-352e-41b1-9329-03a791f8d4ef/4b0d7fdd-6e9b-443a-a44e-a8b1508ce4bc/0/checkpoint/pipeline.config', 'data_object_name': 'd8e83b34-352e-41b1-9329-03a791f8d4ef/4b0d7fdd-6e9b-443a-a44e-a8b1508ce4bc/0/checkpoint/model.ckpt.data-00000-of-00001', 'index_object_name': 'd8e83b34-352e-41b1-9329-03a791f8d4ef/4b0d7fdd-6e9b-443a-a44e-a8b1508ce4bc/0/checkpoint/model.ckpt.index'}}\n",
      "d8e83b34-352e-41b1-9329-03a791f8d4ef/4b0d7fdd-6e9b-443a-a44e-a8b1508ce4bc/0/checkpoint/model.ckpt.index\n",
      "iciiiiiii d8e83b34-352e-41b1-9329-03a791f8d4ef/4b0d7fdd-6e9b-443a-a44e-a8b1508ce4bc/0/checkpoint/model.ckpt.index\n",
      "{'project_token': 'd8e83b34-352e-41b1-9329-03a791f8d4ef', 'object_name': 'd8e83b34-352e-41b1-9329-03a791f8d4ef/4b0d7fdd-6e9b-443a-a44e-a8b1508ce4bc/0/checkpoint/model.ckpt.index'}\n",
      "Downloading d8e83b34-352e-41b1-9329-03a791f8d4ef/4b0d7fdd-6e9b-443a-a44e-a8b1508ce4bc/0/checkpoint/model.ckpt.index\n",
      "[=================================================>]Checkpoint Index downloaded\n",
      "{'project_token': 'd8e83b34-352e-41b1-9329-03a791f8d4ef', 'object_name': 'd8e83b34-352e-41b1-9329-03a791f8d4ef/4b0d7fdd-6e9b-443a-a44e-a8b1508ce4bc/0/checkpoint/model.ckpt.data-00000-of-00001'}\n",
      "Downloading d8e83b34-352e-41b1-9329-03a791f8d4ef/4b0d7fdd-6e9b-443a-a44e-a8b1508ce4bc/0/checkpoint/model.ckpt.data-00000-of-00001\n",
      "[==                                                ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====                                             ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========                                         ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============                                     ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=================                                 ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=======================                           ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==========================                        ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==============================                    ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[==================================                ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=====================================             ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=========================================         ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[=============================================     ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[================================================= ]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub message rate exceeded.\n",
      "The notebook server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--NotebookApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "NotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "NotebookApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotations pulled ...\n",
      "Generating labelmap ...\n",
      "Label_map.pbtxt cr√©e @ d8e83b34-352e-41b1-9329-03a791f8d4ef/4b0d7fdd-6e9b-443a-a44e-a8b1508ce4bc/3/label_map.pbtxt\n",
      "Downloading PNG images to your machine ...\n",
      "416 Images used for training, 104 Images used for validation\n",
      "520 files were already on your machine\n",
      " 0 PNG images have been downloaded to your machine\n",
      "Sending repartition to Picsell.ia backend\n",
      "Repartition send ..\n"
     ]
    }
   ],
   "source": [
    "clt = Client(api_token=api_token, host=\"https://backstage.picsellia.com/sdk/\")\n",
    "clt.init_project(project_token=project_token)\n",
    "clt.init_model(model_name)\n",
    "\n",
    "clt.dl_annotations()\n",
    "clt.generate_labelmap()\n",
    "clt.local_pic_save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ubuntu/picselliaT/object_detection/utils/label_map_util.py:138: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
      "\n",
      "WARNING:tensorflow:From /home/ubuntu/picselliaT/main.py:71: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "main.create_record_files(label_path=clt.label_path, record_dir=clt.record_dir,\n",
    "                         tfExample_generator=clt.tf_vars_generator, annotation_type=annotation_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sv6vKXsNKjWs"
   },
   "source": [
    "Here we edit the base protobuf configuration of our model with our parameters. \n",
    "We check if it the first training on this model to see if we should train from a previous checkpoint or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109
    },
    "colab_type": "code",
    "id": "DOgkvSDwKjWu",
    "outputId": "c7f4aeed-ac53-4df8-d91d-e51ebb29ec83"
   },
   "outputs": [],
   "source": [
    "main.edit_config(model_selected=clt.model_selected, config_output_dir=clt.config_dir,\n",
    "            record_dir=clt.record_dir, \n",
    "            label_map_path=clt.label_path, \n",
    "            num_steps=nb_steps,\n",
    "            batch_size=batch_size, \n",
    "            learning_rate=learning_rate,\n",
    "            annotation_type=annotation_type,\n",
    "            size=500,\n",
    "            eval_number = len(clt.eval_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7TIdFiqvKjW0"
   },
   "source": [
    "## Training\n",
    "\n",
    "We can launch the training... and it's as easy as just telling the fonction where is the configuration file and where we want the checkpoints and records to be saved !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "eYkGBEvnKjW1",
    "outputId": "33501fe1-bbae-4961-8d4f-4435c9ece68d",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main.train(ckpt_dir=clt.checkpoint_dir, \n",
    "                     conf_dir=clt.config_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SJZiDV6aKjW5"
   },
   "source": [
    "Now that the training has ended we want to send the logs to our dashboard so we can neatly see the sweet decrease of the loss. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QpKJL3l6KjW6",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dict_log = main.tfevents_to_dict(path=clt.checkpoint_dir)\n",
    "clt.send_logs(dict_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DhXEFt43KjW9"
   },
   "source": [
    "## Exporting and infering\n",
    "\n",
    "The model is trained but we still need to export it to a Tensorflow graph proto to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sfT1MFkIKjW-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main.export_infer_graph(ckpt_dir=clt.checkpoint_dir, \n",
    "                       exported_model_dir=clt.exported_model, \n",
    "                       pipeline_config_path=clt.config_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1UrcdpZyKjXD"
   },
   "source": [
    "Now we will use the exported model to do some inference on our evaluation set, then send the results to the dashboard.\n",
    "You can set the minimum confidence treshold at which we keep the bounding boxes to the value you like the most."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ke4Jh6J9KjXE",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "min_score_thresh = 0.3 \n",
    "infer(clt.eval_list, exported_model_dir=clt.exported_model, \n",
    "          label_map_path=clt.label_path, results_dir=clt.results_dir, min_score_thresh=min_score_thresh, num_infer=16)\n",
    "clt.send_examples()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clt.send_weights(clt.exported_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main.evaluate(clt.log_dir, clt.config_dir, clt.checkpoint_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "notebookOBDTC.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
