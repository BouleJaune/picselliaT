{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Environment (conda_tensorflow_p36)",
      "language": "python",
      "name": "conda_tensorflow_p36"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.10"
    },
    "colab": {
      "name": "notebookOBDTC.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaoLlAKrK41G",
        "colab_type": "text"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/BouleJaune/picselliaT/blob/master/notebookOBDTC.ipynb)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6t3am_CDKjWU",
        "colab_type": "text"
      },
      "source": [
        "# Object-detection made easy\n",
        "We will learn how to easily train an object detection model from a list of pre-trained models with the dataset you created on the picsell-IA platform."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKI8bKgUWGgo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b49d11f0-2cf2-4392-a7a5-d3c5ba97c89a"
      },
      "source": [
        "import sys\n",
        "sys.path.append(\"slim\")\n",
        "print(sys.path)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['', '/env/python', '/usr/lib/python36.zip', '/usr/lib/python3.6', '/usr/lib/python3.6/lib-dynload', '/usr/local/lib/python3.6/dist-packages', '/usr/lib/python3/dist-packages', '/usr/local/lib/python3.6/dist-packages/IPython/extensions', '/root/.ipython', 'slim']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bS6pLrgacUg7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 146
        },
        "outputId": "b8aba114-93b4-4591-fe77-11c11a2b5d32"
      },
      "source": [
        "!git clone https://github.com/BouleJaune/picselliaT"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'picselliaT'...\n",
            "remote: Enumerating objects: 1090, done.\u001b[K\n",
            "remote: Counting objects: 100% (1090/1090), done.\u001b[K\n",
            "remote: Compressing objects: 100% (727/727), done.\u001b[K\n",
            "remote: Total 1090 (delta 373), reused 1068 (delta 354), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (1090/1090), 26.03 MiB | 25.75 MiB/s, done.\n",
            "Resolving deltas: 100% (373/373), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0QwFhF19ciCa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eb9bac21-a16a-4302-8e4b-5b6d605f4229"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "picselliaT  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9L8vI2RbhwY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 586
        },
        "outputId": "96480bc7-9913-44ed-df32-5ae893c7f162"
      },
      "source": [
        "%cd picselliaT/\n",
        "!pip install picsellia\n",
        "%tensorflow_version 1.x"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/picselliaT\n",
            "Collecting picsellia\n",
            "  Downloading https://files.pythonhosted.org/packages/74/4d/291805521acedfb7904ca9a6ab3649e89261c10a66a0e25d91899f0d3925/picsellia-0.2.41.tar.gz\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (from picsellia) (4.1.2.30)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from picsellia) (2.23.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.6/dist-packages (from picsellia) (7.0.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from picsellia) (1.18.4)\n",
            "Requirement already satisfied: cvxpy in /usr/local/lib/python3.6/dist-packages (from picsellia) (1.0.31)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->picsellia) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->picsellia) (2.9)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->picsellia) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->picsellia) (3.0.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from cvxpy->picsellia) (1.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from cvxpy->picsellia) (0.70.9)\n",
            "Requirement already satisfied: scs>=1.1.3 in /usr/local/lib/python3.6/dist-packages (from cvxpy->picsellia) (2.1.2)\n",
            "Requirement already satisfied: ecos>=2 in /usr/local/lib/python3.6/dist-packages (from cvxpy->picsellia) (2.0.7.post1)\n",
            "Requirement already satisfied: osqp>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from cvxpy->picsellia) (0.6.1)\n",
            "Requirement already satisfied: dill>=0.3.1 in /usr/local/lib/python3.6/dist-packages (from multiprocess->cvxpy->picsellia) (0.3.1.1)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from osqp>=0.4.1->cvxpy->picsellia) (0.16.0)\n",
            "Building wheels for collected packages: picsellia\n",
            "  Building wheel for picsellia (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for picsellia: filename=picsellia-0.2.41-cp36-none-any.whl size=11393 sha256=3700f70aa91cf7b88a144c46e8759ed7c367d55233dba039f37618c4def4f645\n",
            "  Stored in directory: /root/.cache/pip/wheels/49/cc/ca/5b31617387256247be3e2b9c0f2337ac04ff4ffa5cca06f9b7\n",
            "Successfully built picsellia\n",
            "Installing collected packages: picsellia\n",
            "Successfully installed picsellia-0.2.41\n",
            "`%tensorflow_version` only switches the major version: 1.x or 2.x.\n",
            "You set: `1.4`. This will be interpreted as: `1.x`.\n",
            "\n",
            "\n",
            "TensorFlow 1.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XhntBjQuKjWV",
        "colab_type": "text"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ZeMjhE6jKjWY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "1c217019-943a-4fd1-bfb7-723c621452be"
      },
      "source": [
        "from picsellia import Client\n",
        "import main\n",
        "from util.infer import infer\n",
        "import tensorflow as tf"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MYlIZgv9KjWe",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "## List of possible models : \n",
        "\n",
        "- Mask RCNN, a segmentation model. String variable: 'mask_rcnn'\n",
        "- Faster RCNN an accurate but slow object detection model. String variable: 'faster_rcnn'\n",
        "- SSD Inception, a fast but less accurate object detection model. String variable : 'ssd_inception'\n",
        "\n",
        "## Setup\n",
        "\n",
        "We need to start setting up some variables before anything else."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "5g9FPMCdKjWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "token = \"f2a5daec-e0cc-4ea8-a5eb-10d04fd1e153\" # Token from the picsell-IA platform\n",
        "model_picked = \"faster_rcnn\" # Choose your base model here from the list of possible models\n",
        "model_name = \"faster_rcnn\" # Name your to-be trained model\n",
        "annotation_type = \"rectangle\" # Chose the type of annotation used\n",
        "\n",
        "batch_size = 1\n",
        "learning_rate = None #You can let this value to None\n",
        "nb_steps = 20000\n",
        "mask_type = None #Set this to 'PNG_MASKS' if you want to train a mask segmentation model."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UPNfFH5_KjWl",
        "colab_type": "text"
      },
      "source": [
        "## Client initialisation and data pre-processing\n",
        "\n",
        "We communicate with the platform to create a new model and get the images and annotations.\n",
        "With this we can generate the label map, smartly split our data then create the TFRecord files which will be used as input for the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "dUq-cDBVKjWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_models = \"models/\"\n",
        "model_selected = path_models + model_picked + \"/\"\n",
        "\n",
        "clt = Client(token=token, host=\"https://backstage.picsellia.com/sdk/\")\n",
        "clt.init_model(model_name)\n",
        "\n",
        "clt.dl_annotations()\n",
        "clt.generate_labelmap()\n",
        "clt.local_pic_save()\n",
        "\n",
        "main.create_record_files(label_path=clt.label_path, record_dir=clt.record_dir, \n",
        "                         tfExample_generator=clt.tf_vars_generator, annotation_type=annotation_type)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sv6vKXsNKjWs",
        "colab_type": "text"
      },
      "source": [
        "Here we edit the base protobuf configuration of our model with our parameters. \n",
        "We check if it the first training on this model to see if we should train from a previous checkpoint or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOgkvSDwKjWu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if clt.training_id!=0:\n",
        "    previous_path = clt.base_dir.split(\"/\")[:-1]\n",
        "    previous_path[-1] = clt.training_id - 1\n",
        "    model_selected = \"{}/{}/{}/\".format(*previous_path)+\"checkpoint/\"\n",
        "    \n",
        "main.edit_config(model_selected=model_selected, config_output_dir=clt.config_dir,\n",
        "            record_dir=clt.record_dir, \n",
        "            label_map_path=clt.label_path, \n",
        "            masks=mask_type, \n",
        "            num_steps=nb_steps,\n",
        "            batch_size=batch_size, \n",
        "            learning_rate=learning_rate,\n",
        "            training_id=clt.training_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7TIdFiqvKjW0",
        "colab_type": "text"
      },
      "source": [
        "## Training\n",
        "\n",
        "We can launch the training... and it's as easy as just telling the fonction where is the configuration file and where we want the checkpoints and records to be saved !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "eYkGBEvnKjW1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "main.legacy_train(ckpt_dir=clt.checkpoint_dir, \n",
        "                     conf_dir=clt.config_dir)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJZiDV6aKjW5",
        "colab_type": "text"
      },
      "source": [
        "Now that the training has ended we want to send the logs to our dashboard so we can neatly see the sweet decrease of the loss. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "QpKJL3l6KjW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dict_log = main.tfevents_to_dict(path=clt.checkpoint_dir)\n",
        "clt.send_logs(dict_log)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DhXEFt43KjW9",
        "colab_type": "text"
      },
      "source": [
        "## Exporting and infering\n",
        "\n",
        "The model is trained but we still need to export it to a Tensorflow graph proto to use it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "sfT1MFkIKjW-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tf.reset_default_graph()\n",
        "main.export_infer_graph(ckpt_dir=clt.checkpoint_dir, \n",
        "                       exported_model_dir=clt.exported_model, \n",
        "                       pipeline_config_path=clt.config_dir,\n",
        "                       write_inference_graph=True, input_type=\"image_tensor\", input_shape=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1UrcdpZyKjXD",
        "colab_type": "text"
      },
      "source": [
        "Now we will use the exported model to do some inference on our evaluation set, then send the results to the dashboard.\n",
        "You can set the minimum confidence treshold at which we keep the bounding boxes to the value you like the most."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ke4Jh6J9KjXE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "min_score_thresh = 0.6 \n",
        "infer(clt.eval_list, exported_model_dir=clt.exported_model, \n",
        "          label_map_path=clt.label_path, results_dir=clt.results_dir, min_score_thresh=min_score_thresh)\n",
        "clt.send_examples()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}